{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8db71878-f1f2-46ba-8215-0ebe063aa663",
   "metadata": {},
   "source": [
    "**Spam Detection with Naive Bayes Classifier: A Text Classification Journey**\n",
    "\n",
    "__Objective__:\n",
    "Detecting spam msg is crucial for maintaining a clean inbox and preventing potential security threats. This project utilizes a Multinomial Naive Bayes classifier to distinguish between spam and non-spam (ham) emails. The classifier is trained on a dataset containing labeled email messages and employs text preprocessing techniques to enhance the accuracy of predictions.\n",
    "\n",
    "__Key Steps__:\n",
    "\n",
    "__Data Preprocessing__: The dataset, consisting of  messages labeled as spam or ham, undergoes preprocessing. This involves converting text to lowercase, removing punctuation, and filtering out stopwords to enhance the quality of the text data.\n",
    "\n",
    "__Dataset Splitting__: The preprocessed dataset is divided into training and testing sets using the train_test_split function. This ensures that the model is trained on a portion of the data and evaluated on unseen samples to assess its generalization performance.\n",
    "\n",
    "__Feature Extraction__: Text data is converted into a numerical format using the CountVectorizer from scikit-learn. This step transforms text into a bag-of-words representation, capturing the frequency of words in each document.\n",
    "\n",
    "__Model Training__: A Multinomial Naive Bayes classifier is initialized and trained using the vectorized training data. Naive Bayes classifiers are well-suited for text classification tasks due to their simplicity and efficiency.\n",
    "\n",
    "__Model Evaluation__: The trained classifier is evaluated on the testing data to measure its performance. Metrics such as accuracy and classification report are computed to assess the classifier's ability to correctly classify spam and ham emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1517ea68-65f0-4faf-8a49-bdfd42467ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aCER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: ['ham' 'ham' 'spam' ... 'ham' 'ham' 'spam']\n",
      "Accuracy: 0.9802690582959641\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99       965\n",
      "        spam       0.97      0.88      0.92       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.94      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nltk\n",
    "from joblib import dump\n",
    "\n",
    "# Download NLTK stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('spam.csv', encoding='latin1')\n",
    "\n",
    "# Define function for text preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    text = ' '.join(filtered_words)\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing to the 'text' column\n",
    "data['v2'] = data['v2'].apply(preprocess_text)\n",
    "\n",
    "# Split the preprocessed dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['v2'], data['v1'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the CountVectorizer to convert text into bag-of-words representation\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Save the vocabulary\n",
    "vocab = vectorizer.vocabulary_\n",
    "dump(vocab, 'vocab.pkl')\n",
    "\n",
    "# Initialize and train the Multinomial Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_vec, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = nb_classifier.predict(X_test_vec)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print predictions and evaluation metrics\n",
    "print(\"Predictions:\", y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd049b3f-15ae-4033-a6a8-ec9eae239fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5198872d-fc39-4d0a-b2ef-1e05127f0c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y pred ['spam']\n"
     ]
    }
   ],
   "source": [
    "with open('vocab.pkl', 'rb') as f:\n",
    "    vocab = joblib.load(f)\n",
    "\n",
    "# Initialize a new CountVectorizer with the loaded vocabulary\n",
    "vectorizer = CountVectorizer(vocabulary=vocab)\n",
    "\n",
    "joblib.dump(nb_classifier, 'nb_classifier_model.pkl')\n",
    "loaded_nb_classifier = joblib.load('nb_classifier_model.pkl')\n",
    "preprocessed_text = preprocess_text(test)\n",
    "text_vec = vectorizer.transform([preprocessed_text])\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "y_pred_loaded = loaded_nb_classifier.predict(text_vec)\n",
    "\n",
    "#y_pred = nb_classifier.predict(text_vec)\n",
    "print(\"y pred\",y_pred_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cc68f3-57c0-4334-a861-4e8166ce224b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13905d04-d9c3-4627-95b6-0d936ab7d59c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
